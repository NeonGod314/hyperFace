{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubhamkumar.singh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391, 6)\n",
      "here2:  (2, 391)\n",
      "shape of input data:  (391, 227, 227, 3)\n",
      "shape of target variable:  (391, 2)\n",
      "shape of y_coord:  (391, 42)\n",
      "shape of y_visibility:  (391, 21)\n",
      "shape of y_pose:  (391, 3)\n",
      "shape of y_gender:  (391, 2)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from hpf_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391, 6)\n",
      "here2:  (2, 391)\n",
      "shape of input data:  (391, 227, 227, 3)\n",
      "shape of target variable:  (391, 2)\n",
      "shape of y_coord:  (391, 42)\n",
      "shape of y_visibility:  (391, 21)\n",
      "shape of y_pose:  (391, 3)\n",
      "shape of y_gender:  (391, 2)\n",
      "(391, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, y_coord, y_visibility, y_pose, y_gender = load_data()\n",
    "\n",
    "X_test = X_train[int(0.8*len(X_train)):]\n",
    "\n",
    "Y_test = Y_train[int(0.8*len(Y_train)):]\n",
    "\n",
    "X_train = X_train[0:int(0.8*len(X_train))]\n",
    "print(Y_train.shape)\n",
    "Y_train = Y_train[0:int(0.8*len(Y_train))]\n",
    "\n",
    "gender_train = y_gender[0:int(0.8*len(y_gender))]\n",
    "gender_test  = y_gender[int(0.8*len(y_gender)):0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    X = tf.placeholder(tf.float32, [None, 227, 227, 3])\n",
    "    Y = tf.placeholder(tf.float32,[None, 2])\n",
    "    y_coord = tf.placeholder(tf.float32, [None, 42])\n",
    "    y_visibility = tf.placeholder(tf.float32, [None, 21])\n",
    "    y_pose = tf.placeholder(tf.float32, [None, 3])\n",
    "    y_gender = tf.placeholder(tf.float32, [None, 2])\n",
    "    \n",
    "    return X, Y, y_coord, y_visibility, y_pose, y_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    tf.set_random_seed(1)\n",
    "    W1  = tf.get_variable(\"W1\", [11,11, 3,96], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W2  = tf.get_variable(\"W2\", [5,5, 96,256], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W3  = tf.get_variable(\"W3\", [3,3,256,384], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W4  = tf.get_variable(\"W4\", [3,3,384,384], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W5  = tf.get_variable(\"W5\", [3,3,384,256], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "\n",
    "    W1A   = tf.get_variable(\"W1A\",[4,4, 96,256], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W3A   = tf.get_variable(\"W3A\",[2,2,384,256], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W_ALL = tf.get_variable(\"W_ALL\",[1,1,768,192], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    #W1A = tf.get_variable(\"W1A\",[4,4, 96,256], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    parameters = {\"W1\":W1,\n",
    "                 \"W2\":W2,\n",
    "                 \"W3\":W3,\n",
    "                 \"W4\":W4,\n",
    "                 \"W5\":W5,\n",
    "                 \"bc1\": tf.Variable(tf.constant(0.0, shape=[96]),        name=\"bc1\"),\n",
    "                 \"bc2\": tf.Variable(tf.constant(1.0, shape=[256]),       name=\"bc2\"),\n",
    "                 \"bc3\": tf.Variable(tf.constant(0.0, shape=[384]),       name=\"bc3\"),\n",
    "                 \"bc4\": tf.Variable(tf.constant(1.0, shape=[384]),       name=\"bc4\"),\n",
    "                 \"bc5\": tf.Variable(tf.constant(1.0, shape=[256]),       name=\"bc5\"),\n",
    "                 #\"bf1\": tf.Variable(tf.constant(1.0, shape=[120]),       name=\"bf1\"),\n",
    "                 #\"bf2\": tf.Variable(tf.constant(1.0, shape=[84]),        name=\"bf2\"),\n",
    "                 #\"bf3\": tf.Variable(tf.constant(1.0, shape=[2]),         name=\"bf3\")\n",
    "                 \"W1A\": W1A,\n",
    "                 \"W3A\": W3A,\n",
    "                 \"W_ALL\": W_ALL}\n",
    "\n",
    "    return parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "    W4 = parameters['W4']\n",
    "    W5 = parameters['W5']\n",
    "    bc1 = parameters['bc1']\n",
    "    bc2 = parameters['bc2']\n",
    "    bc3 = parameters['bc3']\n",
    "    bc4 = parameters['bc4']\n",
    "    bc5 = parameters['bc5']\n",
    "    W1A = parameters['W1A']\n",
    "    W3A = parameters['W3A']\n",
    "    W_ALL = parameters['W_ALL']\n",
    "    \n",
    "    #layer1\n",
    "    X1 = tf.nn.conv2d(X, W1, strides = [1,4,4,1], padding ='VALID')\n",
    "    Z1 = tf.nn.bias_add(X1, bc1)\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    print(\"A1: \", A1)\n",
    "    L1 = tf.nn.local_response_normalization(A1, depth_radius=5.0, bias=2.0, alpha=1e-4, beta=0.75)\n",
    "    P1 = tf.nn.max_pool(L1, ksize=[1,3,3,1],strides=[1,2,2,1], padding='VALID')\n",
    "    print(\"P1: \", P1)\n",
    "    #layer2\n",
    "    X2 = tf.nn.conv2d(P1, W2, strides = [1,1,1,1], padding ='SAME')\n",
    "    Z2 = tf.nn.bias_add(X2, bc2)\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    print(\"A2: \", A2)\n",
    "    L2 = tf.nn.local_response_normalization(A2, depth_radius=5.0, bias=2.0, alpha=1e-4, beta=0.75)\n",
    "    P2 = tf.nn.max_pool(L2, ksize=[1,3,3,1],strides=[1,2,2,1], padding='VALID')\n",
    "    print(\"P2: \", P2)\n",
    "    #layer3\n",
    "    X3 = tf.nn.conv2d(P2, W3, strides = [1,1,1,1], padding ='SAME')\n",
    "    print(\"X3: \", X3)\n",
    "    Z3 = tf.nn.bias_add(X3, bc3)\n",
    "    P3 = tf.nn.relu(Z3)\n",
    "    #layer4\n",
    "    X4 = tf.nn.conv2d(P3, W4, strides = [1,1,1,1], padding ='SAME')\n",
    "    print(\"X4: \", X4)\n",
    "    Z4 = tf.nn.bias_add(X4, bc4)\n",
    "    P4 = tf.nn.relu(Z4)\n",
    "    #layer5\n",
    "    X5 = tf.nn.conv2d(P4, W5, strides = [1,1,1,1], padding ='SAME')\n",
    "    print(\"X5: \", X5)\n",
    "    Z5 = tf.nn.bias_add(X5, bc5)\n",
    "    A5 = tf.nn.relu(Z5)\n",
    "    P5 = tf.nn.max_pool(A5, ksize=[1,3,3,1],strides=[1,2,2,1], padding='VALID')\n",
    "    print(\"P5: \", P5)\n",
    "    #layer1a\n",
    "    Z1A = tf.nn.conv2d(P1, W1A, strides = [1,4,4,1], padding ='VALID')\n",
    "    print(\"Z1A: \", Z1A)\n",
    "    A1A = tf.nn.relu(Z1A)\n",
    "    #layer3a\n",
    "    Z3A = tf.nn.conv2d(P3, W3A, strides = [1,2,2,1], padding ='VALID')\n",
    "    print(\"Z3A: \", Z3A)\n",
    "    A3A = tf.nn.relu(Z3A)\n",
    "    \n",
    "    #concat\n",
    "    concat = tf.concat([A1A, A3A, P5], 3)\n",
    "    print(\"concat: \", concat)\n",
    "    #CONV_ALL\n",
    "    Z_ALL = tf.nn.conv2d(concat, W_ALL, strides = [1,1,1,1], padding ='VALID')\n",
    "    A_ALL = tf.nn.relu(Z_ALL)\n",
    "    \n",
    "    P = tf.contrib.layers.flatten(A_ALL)\n",
    "    #fully_connected_1\n",
    "    shape_fc =int(np.prod(A_ALL.get_shape()[1:]))\n",
    "    print(\"shape: \", shape_fc)\n",
    "    fc_full_w = tf.Variable(tf.truncated_normal(shape = (6912,3072), mean = 0, stddev = 0.1))\n",
    "    fc_full_b = tf.Variable(tf.zeros(3072))\n",
    "    fc_full_z = tf.matmul(P,fc_full_w) + fc_full_b\n",
    "    fc_full_a = tf.nn.relu(fc_full_z)\n",
    "    \n",
    "    #face/non_face\n",
    "    fc_det_w  = tf.Variable(tf.truncated_normal(shape = (3072,512), mean = 0, stddev = 0.1))\n",
    "    fc_det_b  = tf.Variable(tf.zeros(512))\n",
    "    fc_det_z  = tf.matmul(fc_full_a,fc_det_w) + fc_det_b\n",
    "    fc_det_a  = tf.nn.relu(fc_det_z)\n",
    "    \n",
    "    #genger_m/f\n",
    "    fc_gen_w  = tf.Variable(tf.truncated_normal(shape = (3072,512), mean = 0, stddev = 0.1))\n",
    "    fc_gen_b  = tf.Variable(tf.zeros(512))\n",
    "    fc_gen_z  = tf.matmul(fc_full_a,fc_gen_w) + fc_gen_b\n",
    "    fc_gen_a  = tf.nn.relu(fc_gen_z)\n",
    "    \n",
    "    #output_face_detection\n",
    "    face_w = tf.Variable(tf.truncated_normal(shape = (512, 2), mean = 0 , stddev = 0.1))\n",
    "    face_b = tf.Variable(tf.zeros(2))\n",
    "    face_z = tf.matmul(fc_det_a, face_w) + face_b\n",
    "    \n",
    "    #output_gender\n",
    "    gen_w = tf.Variable(tf.truncated_normal(shape = (512, 2), mean = 0 , stddev = 0.01))\n",
    "    gen_b = tf.Variable(tf.zeros(2))\n",
    "    gen_z = tf.matmul(fc_gen_a, gen_w) + gen_b\n",
    "    \n",
    "    a = tf.Print(gen_z, [gen_z], message=\"This is a: \")\n",
    "    aa = tf.Print(face_z,[face_z], message = \"This is aa: \")\n",
    "    return face_z, gen_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z, Y):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z, labels=Y))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train,Y_train,X_test,Y_test, gender_train, gender_test, learning_rate=0.003,\n",
    "         num_epochs=10, minibatch_size=32,print_cost=True):\n",
    "    \n",
    "    ops.reset_default_graph()\n",
    "    tf.set_random_seed(1)\n",
    "    seed=3\n",
    "    \n",
    "    (m,n_H0,n_W0,n_C0) = X_train.shape\n",
    "    n_y = Y_train.shape[1]\n",
    "    n_g = gender_train.shape[1]\n",
    "    \n",
    "    print(\"n_y: \", n_y)\n",
    "    print(\"n_g: \", n_g)\n",
    "    \n",
    "    costs   = []\n",
    "    g_costs = []\n",
    "    \n",
    "    X, Y, y_coord, y_visibility, y_pose, y_gender = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    face, gender = forward_propagation(X, parameters)\n",
    "    \n",
    "    cost   = compute_cost(face, Y)\n",
    "    g_cost = compute_cost(gender, y_gender)\n",
    "    \n",
    "    #optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    optimizer = tf.train.MomentumOptimizer(1e-4, 0.9, use_nesterov=True).minimize(cost)\n",
    "    g_optimizer = tf.train.MomentumOptimizer(1e-4, 0.9, use_nesterov=True).minimize(g_cost)\n",
    "    #g_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(g_cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            minibatch_cost = 0.\n",
    "            g_minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            print(\"gender_train: \", gender_train.shape)\n",
    "            print(\"y shape: \", Y_train.shape)\n",
    "            minibatches = random_mini_batches(X_train, Y_train, gender_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y, minibatch_g) = minibatch\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y})\n",
    "                _ , gen_cost  = sess.run([g_optimizer, g_cost], feed_dict={X:minibatch_X, y_gender:minibatch_g})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "                g_minibatch_cost += gen_cost / num_minibatches\n",
    "                \n",
    "\n",
    "            #print(\"after epoch\")\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                print (\"Cost after epoch %i: %f , %f\" % (epoch, minibatch_cost, g_minibatch_cost))\n",
    "                #print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            \n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "                g_costs.append(g_minibatch_cost)\n",
    "        \n",
    "        \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "        \n",
    "        plt.plot(np.squeeze(g_costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.argmax(face, 1)\n",
    "        predict_gen = tf.argmax(gender, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        g_correct_prediction = tf.equal(predict_gen, tf.argmax(y_gender, 1))\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(accuracy)\n",
    "        g_accuracy = tf.reduce_mean(tf.cast(g_correct_prediction, \"float\"))\n",
    "        print(g_accuracy)\n",
    "        \n",
    "        face_train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        face_test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Face Train Accuracy:\", face_train_accuracy)\n",
    "        print(\"Face Test Accuracy:\", face_test_accuracy)\n",
    "        \n",
    "        gender_train_accuracy = g_accuracy.eval({X: X_train, Y: gender_train})\n",
    "        gender_test_accuracy = accuracy.eval({X: X_test, Y: gender_test})\n",
    "        print(\"Face Train Accuracy:\", gender_train_accuracy)\n",
    "        print(\"Face Test Accuracy:\", gender_test_accuracy)\n",
    "            \n",
    "            \n",
    "        return train_accuracy, test_accuracy, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_y:  2\n",
      "n_g:  2\n",
      "A1:  Tensor(\"Relu:0\", shape=(?, 55, 55, 96), dtype=float32)\n",
      "P1:  Tensor(\"MaxPool:0\", shape=(?, 27, 27, 96), dtype=float32)\n",
      "A2:  Tensor(\"Relu_1:0\", shape=(?, 27, 27, 256), dtype=float32)\n",
      "P2:  Tensor(\"MaxPool_1:0\", shape=(?, 13, 13, 256), dtype=float32)\n",
      "X3:  Tensor(\"Conv2D_2:0\", shape=(?, 13, 13, 384), dtype=float32)\n",
      "X4:  Tensor(\"Conv2D_3:0\", shape=(?, 13, 13, 384), dtype=float32)\n",
      "X5:  Tensor(\"Conv2D_4:0\", shape=(?, 13, 13, 256), dtype=float32)\n",
      "P5:  Tensor(\"MaxPool_2:0\", shape=(?, 6, 6, 256), dtype=float32)\n",
      "Z1A:  Tensor(\"Conv2D_5:0\", shape=(?, 6, 6, 256), dtype=float32)\n",
      "Z3A:  Tensor(\"Conv2D_6:0\", shape=(?, 6, 6, 256), dtype=float32)\n",
      "concat:  Tensor(\"concat:0\", shape=(?, 6, 6, 768), dtype=float32)\n",
      "shape:  6912\n",
      "WARNING:tensorflow:From <ipython-input-7-590eb251d35e>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "gender_train:  (312, 2)\n",
      "y shape:  (312, 2)\n",
      "m:  312\n"
     ]
    }
   ],
   "source": [
    "_, _, parameters = model(X_train,Y_train,X_test,Y_test, gender_train, gender_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
